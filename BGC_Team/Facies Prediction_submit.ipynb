{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facies Classification Solution By Team_BGC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheolkyun Jeong and Ping Zhang From Team_BGC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### import basic function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "##### import stuff from scikit learn\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score,LeavePGroupsOut, LeaveOneGroupOut, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Prepocessing\n",
    "\n",
    "1) Filtered data preparation\n",
    "\n",
    "After the initial data validation, we figure out the NM_M input is a key differentiator to group non-marine stones (sandstone, c_siltstone, and f_siltstone) and marine stones (marine_silt_shale, mudstone, wakestone, dolomite, packstone, and bafflestone) in the current field. Our team decides to use this classifier aggressively and prepare a filtered dataset which cleans up the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "facies_vector_path = 'facies_vectors.csv'\n",
    "train_path = 'training_data.csv'\n",
    "test_path = 'validation_data_nofacies.csv'\n",
    "# Read training data to dataframe\n",
    "#training_data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Full data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1=sandstone  2=c_siltstone   3=f_siltstone # 4=marine_silt_shale \n",
    "#5=mudstone 6=wackestone 7=dolomite 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041', '#DC7633','#A569BD',\n",
    "       '#000000', '#000080', '#2E86C1', '#AED6F1', '#196F3D']\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(facies_vector_path)\n",
    "X = training_data[feature_names].values\n",
    "y = training_data['Facies'].values\n",
    "well = training_data['Well Name'].values\n",
    "depth = training_data['Depth'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4095, 12)\n"
     ]
    }
   ],
   "source": [
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "training_data.loc[:,'FaciesLabels'] = training_data.apply(lambda row: label_facies(row, facies_labels), axis=1)\n",
    "training_data.describe()\n",
    "\n",
    "# Fitering out some outliers\n",
    "j = []\n",
    "for i in range(len(training_data)):\n",
    "    if ((training_data['NM_M'].values[i]==2)and ((training_data['Facies'].values[i]==1)or(training_data['Facies'].values[i]==2)or(training_data['Facies'].values[i]==3))):\n",
    "        j.append(i)\n",
    "    elif((training_data['NM_M'].values[i]==1)and((training_data['Facies'].values[i]!=1)and(training_data['Facies'].values[i]!=2)and(training_data['Facies'].values[i]!=3))):\n",
    "        j.append(i)\n",
    "\n",
    "training_data_filtered = training_data.drop(training_data.index[j])\n",
    "print(np.shape(training_data_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Missing PE by following AR4 Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X = training_data_filtered[feature_names].values\n",
    "# Testing without filtering\n",
    "X = training_data[feature_names].values\n",
    "\n",
    "reg = RandomForestRegressor(max_features='sqrt', n_estimators=50)\n",
    "# DataImpAll = training_data_filtered[feature_names].copy()\n",
    "DataImpAll = training_data[feature_names].copy()\n",
    "DataImp = DataImpAll.dropna(axis = 0, inplace=False)\n",
    "Ximp=DataImp.loc[:, DataImp.columns != 'PE']\n",
    "Yimp=DataImp.loc[:, 'PE']\n",
    "reg.fit(Ximp, Yimp)\n",
    "X[np.array(DataImpAll.PE.isnull()),4] = reg.predict(DataImpAll.loc[DataImpAll.PE.isnull(),:].drop('PE',axis=1,inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Plot of Facies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SS      268\n",
       "CSiS    940\n",
       "FSiS    780\n",
       "SiSh    271\n",
       "MS      296\n",
       "WS      582\n",
       "D       141\n",
       "PS      686\n",
       "BS      185\n",
       "Name: Facies, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEYCAYAAABSnD3BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb8e1be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count the number of unique entries for each facies, sort them by\n",
    "#facies number (instead of by number of entries)\n",
    "#facies_counts_filtered = training_data_filtered['Facies'].value_counts().sort_index()\n",
    "facies_counts = training_data['Facies'].value_counts().sort_index()\n",
    "#use facies labels to index each count\n",
    "#facies_counts_filtered.index = facies_labels\n",
    "facies_counts.index = facies_labels\n",
    "\n",
    "#facies_counts_filtered.plot(kind='bar',color=facies_colors, \n",
    "#                   title='Distribution of Filtered Training Data by Facies')\n",
    "facies_counts.plot(kind='bar',color=facies_colors, \n",
    "                   title='Distribution of Filtered Training Data by Facies')\n",
    "#facies_counts_filtered\n",
    "#training_data_filtered.columns\n",
    "#facies_counts_filtered\n",
    "\n",
    "training_data.columns\n",
    "facies_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_facies_labels = training_data['Facies'].values\n",
    "feature_vectors = training_data.drop(['Formation', 'Well Name', 'Depth','Facies','FaciesLabels'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normailization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scaled_features = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(conf):\n",
    "    total_correct = 0.\n",
    "    nb_classes = conf.shape[0]\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "    acc = total_correct/sum(sum(conf))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjacent_facies = np.array([[1], [0,2], [1], [4], [3,5], [4,6,7], [5,7], [5,6,8], [6,7]])\n",
    "\n",
    "def accuracy_adjacent(conf, adjacent_facies):\n",
    "    nb_classes = conf.shape[0]\n",
    "    total_correct = 0.\n",
    "    for i in np.arange(0,nb_classes):\n",
    "        total_correct += conf[i][i]\n",
    "        for j in adjacent_facies[i]:\n",
    "            total_correct += conf[i][j]\n",
    "    return total_correct / sum(sum(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HouMath Team algorithm\n",
    "# Feature windows concatenation function \n",
    "\n",
    "def augment_features_window(X, N_neig):\n",
    "    \n",
    "    # Parameters\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "\n",
    "    # Zero padding\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
    "\n",
    "    # Loop over windows\n",
    "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
    "    for r in np.arange(N_row)+N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HouMath Team algorithm\n",
    "# Feature gradient computation function\n",
    "def augment_features_gradient(X, depth):\n",
    "    \n",
    "    # Compute features gradient\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "        \n",
    "    # Compensate for last missing value\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HouMath Team algorithm\n",
    "# Feature augmentation function\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    \n",
    "    # Augment features\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "    \n",
    "    # Find padded rows\n",
    "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
    "    \n",
    "    return X_aug, padded_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4149, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aug, padded_rows = augment_features(scaled_features, well, depth)\n",
    "X_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4149, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_aug, y, test_size=0.3, random_state=16)\n",
    "X_train_full, X_test_zero, y_train_full, y_test_full = train_test_split(X_aug, y, test_size=0.0, random_state=42)\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score,LeavePGroupsOut, LeaveOneGroupOut, cross_val_predict\n",
    "from classification_utilities import display_cm, display_adj_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_filtered = svm.SVC(C=10, gamma=1)\n",
    "clf_filtered.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized facies classification accuracy = 0.66\n",
      "Optimized adjacent facies classification accuracy = 0.83\n",
      "     Pred    SS  CSiS  FSiS  SiSh    MS    WS     D    PS    BS Total\n",
      "     True\n",
      "       SS    63    19     9           1                            92\n",
      "     CSiS     3   200    90                                       293\n",
      "     FSiS          24   200           1                 1         226\n",
      "     SiSh                21    45     1     4           5          76\n",
      "       MS                26     3    28     9     1    17          84\n",
      "       WS                41     2     6   105          38         192\n",
      "        D                19     1     1     3     9     7     1    41\n",
      "       PS                50                 6         137     1   194\n",
      "       BS                10     1                       3    33    47\n",
      "\n",
      "Precision  0.95  0.82  0.43  0.87  0.74  0.83  0.90  0.66  0.94  0.74\n",
      "   Recall  0.68  0.68  0.88  0.59  0.33  0.55  0.22  0.71  0.70  0.66\n",
      "       F1  0.80  0.75  0.58  0.70  0.46  0.66  0.35  0.68  0.80  0.66\n"
     ]
    }
   ],
   "source": [
    "#predicted_labels_filtered = clf_filtered.predict(X_test_filtered)\n",
    "predicted_labels = clf_filtered.predict(X_test)\n",
    "cv_conf_svm = confusion_matrix(y_test, predicted_labels)\n",
    "print('Optimized facies classification accuracy = %.2f' % accuracy(cv_conf_svm))\n",
    "print('Optimized adjacent facies classification accuracy = %.2f' % accuracy_adjacent(cv_conf_svm, adjacent_facies))\n",
    "display_cm(cv_conf_svm, facies_labels,display_metrics=True, hide_zeros=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "well_data = pd.read_csv('validation_data_nofacies.csv')\n",
    "well_data['Well Name'] = well_data['Well Name'].astype('category')\n",
    "well_features = well_data.drop(['Formation', 'Well Name', 'Depth'], axis=1)\n",
    "# Prepare test data\n",
    "well_ts = well_data['Well Name'].values\n",
    "depth_ts = well_data['Depth'].values\n",
    "X_ts = well_data[feature_names].values\n",
    "X_ts = scaler.transform(X_ts)\n",
    "# Augment features\n",
    "X_ts, padded_rows = augment_features(X_ts, well_ts, depth_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using all data and optimize parameter to train the data\n",
    "clf_filtered = svm.SVC(C=10, gamma=1)\n",
    "clf_filtered.fit(X_train_full, y_train_full)\n",
    "#clf_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = clf_filtered.predict(X_ts)\n",
    "well_data['Facies'] = y_pred\n",
    "well_data\n",
    "well_data.to_csv('predict_result_svm_full_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2904, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_master': '', 'tf_random_seed': None, '_environment': 'local', 'save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000010F577F0>, '_num_ps_replicas': 0, '_is_chief': True, 'save_checkpoints_steps': None, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'keep_checkpoint_every_n_hours': 10000, '_task_id': 0, 'save_checkpoints_secs': 600, '_evaluation_master': '', 'keep_checkpoint_max': 5}\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:fraction_of_zero_values is illegal; using dnn/hiddenlayer_3_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:activation is illegal; using dnn/hiddenlayer_3_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 2.38344, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 1.22716, step = 101\n",
      "INFO:tensorflow:global_step/sec: 68.861\n",
      "INFO:tensorflow:loss = 1.08212, step = 201\n",
      "INFO:tensorflow:global_step/sec: 93.2272\n",
      "INFO:tensorflow:loss = 1.00204, step = 301\n",
      "INFO:tensorflow:global_step/sec: 98.7307\n",
      "INFO:tensorflow:loss = 0.957277, step = 401\n",
      "INFO:tensorflow:global_step/sec: 95.2151\n",
      "INFO:tensorflow:loss = 0.926812, step = 501\n",
      "INFO:tensorflow:global_step/sec: 97.0442\n",
      "INFO:tensorflow:loss = 0.90592, step = 601\n",
      "INFO:tensorflow:global_step/sec: 96.3895\n",
      "INFO:tensorflow:loss = 0.887229, step = 701\n",
      "INFO:tensorflow:global_step/sec: 97.6507\n",
      "INFO:tensorflow:loss = 0.872834, step = 801\n",
      "INFO:tensorflow:global_step/sec: 95.7803\n",
      "INFO:tensorflow:loss = 0.856066, step = 901\n",
      "INFO:tensorflow:global_step/sec: 98.8278\n",
      "INFO:tensorflow:loss = 0.842357, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 94.728\n",
      "INFO:tensorflow:loss = 0.830322, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 99.3581\n",
      "INFO:tensorflow:loss = 0.818153, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 93.7686\n",
      "INFO:tensorflow:loss = 0.809641, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 95.4878\n",
      "INFO:tensorflow:loss = 0.798911, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 96.8752\n",
      "INFO:tensorflow:loss = 0.797683, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 98.8282\n",
      "INFO:tensorflow:loss = 0.781023, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 97.5932\n",
      "INFO:tensorflow:loss = 0.77238, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 99.9741\n",
      "INFO:tensorflow:loss = 0.761827, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 98.3419\n",
      "INFO:tensorflow:loss = 0.754598, step = 1901\n",
      "INFO:tensorflow:global_step/sec: 93.646\n",
      "INFO:tensorflow:loss = 0.744399, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 95.2331\n",
      "INFO:tensorflow:loss = 0.739084, step = 2101\n",
      "INFO:tensorflow:global_step/sec: 96.5756\n",
      "INFO:tensorflow:loss = 0.72911, step = 2201\n",
      "INFO:tensorflow:global_step/sec: 98.4191\n",
      "INFO:tensorflow:loss = 0.722839, step = 2301\n",
      "INFO:tensorflow:global_step/sec: 96.7436\n",
      "INFO:tensorflow:loss = 0.716128, step = 2401\n",
      "INFO:tensorflow:global_step/sec: 99.3185\n",
      "INFO:tensorflow:loss = 0.707455, step = 2501\n",
      "INFO:tensorflow:global_step/sec: 94.2811\n",
      "INFO:tensorflow:loss = 0.702043, step = 2601\n",
      "INFO:tensorflow:global_step/sec: 98.867\n",
      "INFO:tensorflow:loss = 0.694811, step = 2701\n",
      "INFO:tensorflow:global_step/sec: 94.5666\n",
      "INFO:tensorflow:loss = 0.691191, step = 2801\n",
      "INFO:tensorflow:global_step/sec: 95.1788\n",
      "INFO:tensorflow:loss = 0.685121, step = 2901\n",
      "INFO:tensorflow:global_step/sec: 96.5756\n",
      "INFO:tensorflow:loss = 0.684594, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 97.0446\n",
      "INFO:tensorflow:loss = 0.675901, step = 3101\n",
      "INFO:tensorflow:global_step/sec: 94.998\n",
      "INFO:tensorflow:loss = 0.669248, step = 3201\n",
      "INFO:tensorflow:global_step/sec: 96.6134\n",
      "INFO:tensorflow:loss = 0.666258, step = 3301\n",
      "INFO:tensorflow:global_step/sec: 98.1294\n",
      "INFO:tensorflow:loss = 0.662734, step = 3401\n",
      "INFO:tensorflow:global_step/sec: 95.4697\n",
      "INFO:tensorflow:loss = 0.661021, step = 3501\n",
      "INFO:tensorflow:global_step/sec: 98.2648\n",
      "INFO:tensorflow:loss = 0.652258, step = 3601\n",
      "INFO:tensorflow:global_step/sec: 95.2327\n",
      "INFO:tensorflow:loss = 0.652265, step = 3701\n",
      "INFO:tensorflow:global_step/sec: 95.052\n",
      "INFO:tensorflow:loss = 0.645372, step = 3801\n",
      "INFO:tensorflow:global_step/sec: 98.4003\n",
      "INFO:tensorflow:loss = 0.644604, step = 3901\n",
      "INFO:tensorflow:global_step/sec: 99.8941\n",
      "INFO:tensorflow:loss = 0.637486, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 96.6134\n",
      "INFO:tensorflow:loss = 0.634596, step = 4101\n",
      "INFO:tensorflow:global_step/sec: 98.2457\n",
      "INFO:tensorflow:loss = 0.631478, step = 4201\n",
      "INFO:tensorflow:global_step/sec: 97.0069\n",
      "INFO:tensorflow:loss = 0.629633, step = 4301\n",
      "INFO:tensorflow:global_step/sec: 95.052\n",
      "INFO:tensorflow:loss = 0.624992, step = 4401\n",
      "INFO:tensorflow:global_step/sec: 91.6526\n",
      "INFO:tensorflow:loss = 0.624527, step = 4501\n",
      "INFO:tensorflow:global_step/sec: 92.4498\n",
      "INFO:tensorflow:loss = 0.622326, step = 4601\n",
      "INFO:tensorflow:global_step/sec: 94.1209\n",
      "INFO:tensorflow:loss = 0.619874, step = 4701\n",
      "INFO:tensorflow:global_step/sec: 93.5215\n",
      "INFO:tensorflow:loss = 0.617227, step = 4801\n",
      "INFO:tensorflow:global_step/sec: 100.014\n",
      "INFO:tensorflow:loss = 0.61457, step = 4901\n",
      "INFO:tensorflow:global_step/sec: 93.7857\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.612631.\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:fraction_of_zero_values is illegal; using dnn/hiddenlayer_3_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:activation is illegal; using dnn/hiddenlayer_3_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Loading model from checkpoint: C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt-5000-?????-of-00001.\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:fraction_of_zero_values is illegal; using dnn/hiddenlayer_3_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:activation is illegal; using dnn/hiddenlayer_3_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 5000.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 5000: accuracy = 0.619277, loss = 1.11743\n",
      "Accuracy: 0.619277\n",
      "Optimized facies classification accuracy = 0.62\n",
      "Optimized adjacent facies classification accuracy = 0.91\n",
      "     Pred    SS  CSiS  FSiS  SiSh    MS    WS     D    PS    BS Total\n",
      "     True\n",
      "       SS    58    30     4                                        92\n",
      "     CSiS    14   218    56           2     1     1     1         293\n",
      "     FSiS     6    65   146     5     2     2                     226\n",
      "     SiSh                 2    57     5     9           2     1    76\n",
      "       MS           1     1    11    21    36     2    12          84\n",
      "       WS           1     1    27    17    97     2    43     4   192\n",
      "        D                       3     5     2    22     6     3    41\n",
      "       PS                 3     8     7    47     6   115     8   194\n",
      "       BS                       1                 1     8    37    47\n",
      "\n",
      "Precision  0.74  0.69  0.69  0.51  0.36  0.50  0.65  0.61  0.70  0.62\n",
      "   Recall  0.63  0.74  0.65  0.75  0.25  0.51  0.54  0.59  0.79  0.62\n",
      "       F1  0.68  0.72  0.67  0.61  0.29  0.50  0.59  0.60  0.74  0.62\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "# feature_columns_filtered = [tf.contrib.layers.real_valued_column(\"\", dimension=7)]\n",
    "feature_columns_filtered = [tf.contrib.layers.real_valued_column(\"\", dimension=28)]\n",
    "\n",
    "# Build DNN \n",
    "classifier_filtered = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns_filtered,\n",
    "                                            hidden_units=[14, 14, 14, 10],\n",
    "                                            n_classes=10)\n",
    "\n",
    "classifier_filtered.fit(x=X_train,y=y_train,steps=5000)\n",
    "y_predict = []\n",
    "predictions = classifier_filtered.predict(x=X_test)\n",
    "\n",
    "\n",
    "for i, p in enumerate(predictions):\n",
    "    y_predict.append(p)\n",
    "    #print(\"Index %s: Prediction - %s, Real - %s\" % (i + 1, p, y_test_filtered[i]))\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier_filtered.evaluate(x=X_test, y=y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    "\n",
    "cv_conf_dnn = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "print('Optimized facies classification accuracy = %.2f' % accuracy(cv_conf_dnn))\n",
    "print('Optimized adjacent facies classification accuracy = %.2f' % accuracy_adjacent(cv_conf_dnn, adjacent_facies))\n",
    "display_cm(cv_conf_dnn, facies_labels,display_metrics=True, hide_zeros=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:fraction_of_zero_values is illegal; using dnn/hiddenlayer_3_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:activation is illegal; using dnn/hiddenlayer_3_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 0.764196, step = 5001\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.723611, step = 5101\n",
      "INFO:tensorflow:global_step/sec: 51.2992\n",
      "INFO:tensorflow:loss = 0.71196, step = 5201\n",
      "INFO:tensorflow:global_step/sec: 71.3368\n",
      "INFO:tensorflow:loss = 0.705278, step = 5301\n",
      "INFO:tensorflow:global_step/sec: 70.5121\n",
      "INFO:tensorflow:loss = 0.701563, step = 5401\n",
      "INFO:tensorflow:global_step/sec: 72.275\n",
      "INFO:tensorflow:loss = 0.697651, step = 5501\n",
      "INFO:tensorflow:global_step/sec: 69.6768\n",
      "INFO:tensorflow:loss = 0.694526, step = 5601\n",
      "INFO:tensorflow:global_step/sec: 70.5516\n",
      "INFO:tensorflow:loss = 0.690922, step = 5701\n",
      "INFO:tensorflow:global_step/sec: 70.5816\n",
      "INFO:tensorflow:loss = 0.688914, step = 5801\n",
      "INFO:tensorflow:global_step/sec: 70.502\n",
      "INFO:tensorflow:loss = 0.685347, step = 5901\n",
      "INFO:tensorflow:global_step/sec: 72.2854\n",
      "INFO:tensorflow:loss = 0.682657, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 69.7448\n",
      "INFO:tensorflow:loss = 0.680838, step = 6101\n",
      "INFO:tensorflow:global_step/sec: 70.1061\n",
      "INFO:tensorflow:loss = 0.678432, step = 6201\n",
      "INFO:tensorflow:global_step/sec: 69.3189\n",
      "INFO:tensorflow:loss = 0.676384, step = 6301\n",
      "INFO:tensorflow:global_step/sec: 71.3366\n",
      "INFO:tensorflow:loss = 0.674596, step = 6401\n",
      "INFO:tensorflow:global_step/sec: 70.6614\n",
      "INFO:tensorflow:loss = 0.672354, step = 6501\n",
      "INFO:tensorflow:global_step/sec: 70.4622\n",
      "INFO:tensorflow:loss = 0.671409, step = 6601\n",
      "INFO:tensorflow:global_step/sec: 71.4079\n",
      "INFO:tensorflow:loss = 0.669849, step = 6701\n",
      "INFO:tensorflow:global_step/sec: 71.3061\n",
      "INFO:tensorflow:loss = 0.666768, step = 6801\n",
      "INFO:tensorflow:global_step/sec: 69.7834\n",
      "INFO:tensorflow:loss = 0.66397, step = 6901\n",
      "INFO:tensorflow:global_step/sec: 70.7312\n",
      "INFO:tensorflow:loss = 0.663558, step = 7001\n",
      "INFO:tensorflow:global_step/sec: 71.5407\n",
      "INFO:tensorflow:loss = 0.661839, step = 7101\n",
      "INFO:tensorflow:global_step/sec: 70.9216\n",
      "INFO:tensorflow:loss = 0.660069, step = 7201\n",
      "INFO:tensorflow:global_step/sec: 69.7738\n",
      "INFO:tensorflow:loss = 0.660163, step = 7301\n",
      "INFO:tensorflow:global_step/sec: 70.6113\n",
      "INFO:tensorflow:loss = 0.658255, step = 7401\n",
      "INFO:tensorflow:global_step/sec: 70.5316\n",
      "INFO:tensorflow:loss = 0.655927, step = 7501\n",
      "INFO:tensorflow:global_step/sec: 70.5715\n",
      "INFO:tensorflow:loss = 0.654414, step = 7601\n",
      "INFO:tensorflow:global_step/sec: 70.492\n",
      "INFO:tensorflow:loss = 0.651972, step = 7701\n",
      "INFO:tensorflow:global_step/sec: 71.4079\n",
      "INFO:tensorflow:loss = 0.651003, step = 7801\n",
      "INFO:tensorflow:global_step/sec: 70.4524\n",
      "INFO:tensorflow:loss = 0.649422, step = 7901\n",
      "INFO:tensorflow:global_step/sec: 70.5617\n",
      "INFO:tensorflow:loss = 0.648294, step = 8001\n",
      "INFO:tensorflow:global_step/sec: 72.1604\n",
      "INFO:tensorflow:loss = 0.648087, step = 8101\n",
      "INFO:tensorflow:global_step/sec: 68.9941\n",
      "INFO:tensorflow:loss = 0.646671, step = 8201\n",
      "INFO:tensorflow:global_step/sec: 70.5913\n",
      "INFO:tensorflow:loss = 0.644736, step = 8301\n",
      "INFO:tensorflow:global_step/sec: 70.3925\n",
      "INFO:tensorflow:loss = 0.643859, step = 8401\n",
      "INFO:tensorflow:global_step/sec: 67.5768\n",
      "INFO:tensorflow:loss = 0.643228, step = 8501\n",
      "INFO:tensorflow:global_step/sec: 71.3011\n",
      "INFO:tensorflow:loss = 0.641723, step = 8601\n",
      "INFO:tensorflow:global_step/sec: 71.1437\n",
      "INFO:tensorflow:loss = 0.641879, step = 8701\n",
      "INFO:tensorflow:global_step/sec: 70.3727\n",
      "INFO:tensorflow:loss = 0.639464, step = 8801\n",
      "INFO:tensorflow:global_step/sec: 70.0768\n",
      "INFO:tensorflow:loss = 0.638501, step = 8901\n",
      "INFO:tensorflow:global_step/sec: 72.8326\n",
      "INFO:tensorflow:loss = 0.638066, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 70.972\n",
      "INFO:tensorflow:loss = 0.637703, step = 9101\n",
      "INFO:tensorflow:global_step/sec: 69.5894\n",
      "INFO:tensorflow:loss = 0.635716, step = 9201\n",
      "INFO:tensorflow:global_step/sec: 72.2122\n",
      "INFO:tensorflow:loss = 0.634401, step = 9301\n",
      "INFO:tensorflow:global_step/sec: 71.4691\n",
      "INFO:tensorflow:loss = 0.634427, step = 9401\n",
      "INFO:tensorflow:global_step/sec: 68.9181\n",
      "INFO:tensorflow:loss = 0.633336, step = 9501\n",
      "INFO:tensorflow:global_step/sec: 70.5617\n",
      "INFO:tensorflow:loss = 0.633197, step = 9601\n",
      "INFO:tensorflow:global_step/sec: 70.5814\n",
      "INFO:tensorflow:loss = 0.631406, step = 9701\n",
      "INFO:tensorflow:global_step/sec: 71.2857\n",
      "INFO:tensorflow:loss = 0.630644, step = 9801\n",
      "INFO:tensorflow:global_step/sec: 71.3772\n",
      "INFO:tensorflow:loss = 0.628568, step = 9901\n",
      "INFO:tensorflow:global_step/sec: 71.357\n",
      "INFO:tensorflow:loss = 0.627568, step = 10001\n",
      "INFO:tensorflow:global_step/sec: 71.3671\n",
      "INFO:tensorflow:loss = 0.627002, step = 10101\n",
      "INFO:tensorflow:global_step/sec: 69.7641\n",
      "INFO:tensorflow:loss = 0.626503, step = 10201\n",
      "INFO:tensorflow:global_step/sec: 71.357\n",
      "INFO:tensorflow:loss = 0.626151, step = 10301\n",
      "INFO:tensorflow:global_step/sec: 72.3796\n",
      "INFO:tensorflow:loss = 0.624699, step = 10401\n",
      "INFO:tensorflow:global_step/sec: 68.8706\n",
      "INFO:tensorflow:loss = 0.624882, step = 10501\n",
      "INFO:tensorflow:global_step/sec: 69.735\n",
      "INFO:tensorflow:loss = 0.624645, step = 10601\n",
      "INFO:tensorflow:global_step/sec: 70.8614\n",
      "INFO:tensorflow:loss = 0.623144, step = 10701\n",
      "INFO:tensorflow:global_step/sec: 68.5588\n",
      "INFO:tensorflow:loss = 0.62211, step = 10801\n",
      "INFO:tensorflow:global_step/sec: 69.7836\n",
      "INFO:tensorflow:loss = 0.62033, step = 10901\n",
      "INFO:tensorflow:global_step/sec: 70.6612\n",
      "INFO:tensorflow:loss = 0.62051, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 71.4691\n",
      "INFO:tensorflow:loss = 0.620089, step = 11101\n",
      "INFO:tensorflow:global_step/sec: 70.2147\n",
      "INFO:tensorflow:loss = 0.619542, step = 11201\n",
      "INFO:tensorflow:global_step/sec: 72.1913\n",
      "INFO:tensorflow:loss = 0.61847, step = 11301\n",
      "INFO:tensorflow:global_step/sec: 69.8128\n",
      "INFO:tensorflow:loss = 0.617709, step = 11401\n",
      "INFO:tensorflow:global_step/sec: 72.4843\n",
      "INFO:tensorflow:loss = 0.616551, step = 11501\n",
      "INFO:tensorflow:global_step/sec: 69.4734\n",
      "INFO:tensorflow:loss = 0.615809, step = 11601\n",
      "INFO:tensorflow:global_step/sec: 70.5516\n",
      "INFO:tensorflow:loss = 0.615043, step = 11701\n",
      "INFO:tensorflow:global_step/sec: 69.7545\n",
      "INFO:tensorflow:loss = 0.613492, step = 11801\n",
      "INFO:tensorflow:global_step/sec: 70.5316\n",
      "INFO:tensorflow:loss = 0.613749, step = 11901\n",
      "INFO:tensorflow:global_step/sec: 70.5715\n",
      "INFO:tensorflow:loss = 0.613431, step = 12001\n",
      "INFO:tensorflow:global_step/sec: 70.522\n",
      "INFO:tensorflow:loss = 0.613151, step = 12101\n",
      "INFO:tensorflow:global_step/sec: 71.3164\n",
      "INFO:tensorflow:loss = 0.611876, step = 12201\n",
      "INFO:tensorflow:global_step/sec: 69.8034\n",
      "INFO:tensorflow:loss = 0.610612, step = 12301\n",
      "INFO:tensorflow:global_step/sec: 65.8406\n",
      "INFO:tensorflow:loss = 0.610076, step = 12401\n",
      "INFO:tensorflow:global_step/sec: 61.8808\n",
      "INFO:tensorflow:loss = 0.609233, step = 12501\n",
      "INFO:tensorflow:global_step/sec: 68.87\n",
      "INFO:tensorflow:loss = 0.609014, step = 12601\n",
      "INFO:tensorflow:global_step/sec: 68.9696\n",
      "INFO:tensorflow:loss = 0.607997, step = 12701\n",
      "INFO:tensorflow:global_step/sec: 65.1052\n",
      "INFO:tensorflow:loss = 0.608398, step = 12801\n",
      "INFO:tensorflow:global_step/sec: 64.5839\n",
      "INFO:tensorflow:loss = 0.60564, step = 12901\n",
      "INFO:tensorflow:global_step/sec: 67.2694\n",
      "INFO:tensorflow:loss = 0.604723, step = 13001\n",
      "INFO:tensorflow:global_step/sec: 72.1735\n",
      "INFO:tensorflow:loss = 0.604006, step = 13101\n",
      "INFO:tensorflow:global_step/sec: 70.584\n",
      "INFO:tensorflow:loss = 0.604355, step = 13201\n",
      "INFO:tensorflow:global_step/sec: 72.4035\n",
      "INFO:tensorflow:loss = 0.602984, step = 13301\n",
      "INFO:tensorflow:global_step/sec: 71.8623\n",
      "INFO:tensorflow:loss = 0.602673, step = 13401\n",
      "INFO:tensorflow:global_step/sec: 71.5739\n",
      "INFO:tensorflow:loss = 0.600964, step = 13501\n",
      "INFO:tensorflow:global_step/sec: 72.2149\n",
      "INFO:tensorflow:loss = 0.599888, step = 13601\n",
      "INFO:tensorflow:global_step/sec: 72.2149\n",
      "INFO:tensorflow:loss = 0.600564, step = 13701\n",
      "INFO:tensorflow:global_step/sec: 73.1553\n",
      "INFO:tensorflow:loss = 0.599882, step = 13801\n",
      "INFO:tensorflow:global_step/sec: 72.2149\n",
      "INFO:tensorflow:loss = 0.599259, step = 13901\n",
      "INFO:tensorflow:global_step/sec: 71.329\n",
      "INFO:tensorflow:loss = 0.598237, step = 14001\n",
      "INFO:tensorflow:global_step/sec: 73.2304\n",
      "INFO:tensorflow:loss = 0.597469, step = 14101\n",
      "INFO:tensorflow:global_step/sec: 72.1837\n",
      "INFO:tensorflow:loss = 0.59751, step = 14201\n",
      "INFO:tensorflow:global_step/sec: 73.1874\n",
      "INFO:tensorflow:loss = 0.596996, step = 14301\n",
      "INFO:tensorflow:global_step/sec: 72.0069\n",
      "INFO:tensorflow:loss = 0.595568, step = 14401\n",
      "INFO:tensorflow:global_step/sec: 71.646\n",
      "INFO:tensorflow:loss = 0.595532, step = 14501\n",
      "INFO:tensorflow:global_step/sec: 71.329\n",
      "INFO:tensorflow:loss = 0.595475, step = 14601\n",
      "INFO:tensorflow:global_step/sec: 71.2884\n",
      "INFO:tensorflow:loss = 0.594737, step = 14701\n",
      "INFO:tensorflow:global_step/sec: 69.7567\n",
      "INFO:tensorflow:loss = 0.593986, step = 14801\n",
      "INFO:tensorflow:global_step/sec: 71.3292\n",
      "INFO:tensorflow:loss = 0.593696, step = 14901\n",
      "INFO:tensorflow:global_step/sec: 71.3393\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.593106.\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From E:\\Software\\Machine Learning Kit\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:fraction_of_zero_values is illegal; using dnn/hiddenlayer_3_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_3:activation is illegal; using dnn/hiddenlayer_3_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Loading model from checkpoint: C:\\Users\\PZhang7\\AppData\\Local\\Temp\\tmp96w__oru\\model.ckpt-15000-?????-of-00001.\n"
     ]
    }
   ],
   "source": [
    "classifier_filtered.fit(x=X_train_full,\n",
    "               y=y_train_full,\n",
    "               steps=10000)\n",
    "predictions = classifier_filtered.predict(X_ts)\n",
    "y_predict_filtered = []\n",
    "for i, p in enumerate(predictions):\n",
    "    y_predict_filtered.append(p)\n",
    "well_data['Facies'] = y_predict_filtered\n",
    "well_data\n",
    "well_data.to_csv('predict_result_dnn_full_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best model by setting different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_cv = cv_conf_filtered\n",
    "best_arch = []\n",
    "tmp_score = 0\n",
    "tmp_cv = cv_conf_filtered\n",
    "# try 3 layers and each architecture with 10 iterations training\n",
    "for i in range (7, 14):\n",
    "    for j in range(14, 21):\n",
    "        for k in range(10, 14):\n",
    "            for l in range(10):\n",
    "                dim_num = 3\n",
    "                arch = [i,j,k]\n",
    "                s_num = 3000\n",
    "                feature_columns_filtered = [tf.contrib.layers.real_valued_column(\"\", dimension=dim_num)]\n",
    "                dnn = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns_filtered,\n",
    "                                                             hidden_units=arch,\n",
    "                                                             n_classes=10)\n",
    "                tmp_score,tmp_cv = dnn_prediction(dim_num, arch, s_num, dnn)\n",
    "                if(tmp_score>best_score):\n",
    "                    best_score = tmp_score\n",
    "                    best_cv = tmp_cv\n",
    "                    best_arch = arch\n",
    "print('Best facies classification accuracy = %.2f' % accuracy(best_cv))\n",
    "print('Best adjacent facies classification accuracy = %.2f' % accuracy_adjacent(best_cv, adjacent_facies))\n",
    "print('Best arch is ', best_arch)\n",
    "display_cm(cv_conf_dnn, facies_labels,display_metrics=True, hide_zeros=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export_dir_path = 'd:\\\\'\n",
    "#classifier_filtered.export(export_dir_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
